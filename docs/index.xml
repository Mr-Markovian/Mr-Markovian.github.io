<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Conditionally Random on Shashank&#39;s Home</title>
    <link>https://mr-markovian.github.io/</link>
    <description>Recent content in Conditionally Random on Shashank&#39;s Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Shashank Roy</copyright>
    <lastBuildDate>Mon, 11 Apr 2022 11:13:32 -0400</lastBuildDate><atom:link href="https://mr-markovian.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chapter III: Sinkhorn: A short intro to distance on probability measures for machine learning</title>
      <link>https://mr-markovian.github.io/post/chapter-3/</link>
      <pubDate>Mon, 11 Apr 2022 11:13:32 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-3/</guid>
      <description>Given a set of observations ${y1:y_n} \in \mathcal{X}$ which are samples from an unknown distribution $p(y)$, suppose that we would like to produce new samples similar to the above. What one then means is that they are tyring to learn the distribution $p(y)$ itself, through which they can sample new points. A model which will learn the distribuion from the samples and then generate samples from it is called a generative model.</description>
    </item>
    
    <item>
      <title>Resume</title>
      <link>https://mr-markovian.github.io/resume/</link>
      <pubDate>Sun, 27 Feb 2022 23:53:33 +0530</pubDate>
      
      <guid>https://mr-markovian.github.io/resume/</guid>
      <description>Life must be understood backwards but lived forwards. &amp;ndash; Søren Kierkegaard (a 19th-century Danish philosopher)
Shashank Kumar Roy Institution International Centre for Theoretical Sciences - TIFR, Bangalore, India
Current Position PhD Research Scholar, Physics
email shashank.roy@icts.res.in, shashankroy1997@gmail.com,
linkedin https://www.linkedin.com/in/shashankroy/
Projects and Experience Winter Project | International Centre for Theoretical Sciences | October 2019- Dec 2019
Sequential estimation of conditional distribution of the state of a 40-dimensional nonlinear dynamical system with partial obsevrations via Kalman Filtering.</description>
    </item>
    
    <item>
      <title>Machine Learning for Weather and Climate Science</title>
      <link>https://mr-markovian.github.io/post/chapter-10/</link>
      <pubDate>Sun, 13 Jun 2021 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-10/</guid>
      <description>It&amp;rsquo;s a remarkable time for us for application of AI to solve the hardest of real world problems. Climate and weather prediction is one such task which impacts billions of people all over the world.
Of possible areas, some are as follows:
 Downscale data Accelerate Simulations Improve forecasts Emulate complex processes   Pattern recognition for extreme weather phenomenon. Tracking extreme events is critical for our climate if one is to prepare and avoid their devastations.</description>
    </item>
    
    <item>
      <title>Chapter VI: Quantum Alorithms for Optimization</title>
      <link>https://mr-markovian.github.io/post/chapter-11/</link>
      <pubDate>Fri, 14 Apr 2017 11:25:05 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-11/</guid>
      <description>$$\mathcal{H}=\sum_{j,j}s_i s_j$$ Solving optimzation probelms, which deal in finding the best possible solution to a problem under certain constrained. Often at the heart of critical decision making processes in industrial and business problems which are both complex and high-dimensional in nature. Under some conditions, they sometimes become notoriously hard and often ones resorts to best achievable solutions instead of the best solution. To take a refresher of the classical optimization problems as we know it, click here.</description>
    </item>
    
    <item>
      <title>Chapter VI: Tensor networks for Machine Learning</title>
      <link>https://mr-markovian.github.io/post/chapter-12/</link>
      <pubDate>Fri, 14 Apr 2017 11:25:05 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-12/</guid>
      <description>Tensor Networks Graphical models are powerful methods which simplifies the statistical dependence of a set of random variables.
 Bayesian networks Markov Random Fields factor graph model  A factor graphical model descibes a fucntion of the random variables in temrs of the products of fuction of this random variables. when all the factors are non ngative fucntion, the global fucntion can be used to represent a multivariate probability distribution. they capture and can model a lot of problems in fiels of economics, machine learning, statistical modeling and so on.</description>
    </item>
    
    <item>
      <title>Monte Carlo Methods: The Wisdom of the Crowd</title>
      <link>https://mr-markovian.github.io/post/chapter-6/</link>
      <pubDate>Fri, 14 Apr 2017 11:25:05 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chapter V: Data Assimilation: A Hidden markov model problem</title>
      <link>https://mr-markovian.github.io/post/chapter-5/</link>
      <pubDate>Thu, 13 Apr 2017 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chapter VII:Is Finance useful for a Physicist?</title>
      <link>https://mr-markovian.github.io/post/chapter-8/</link>
      <pubDate>Thu, 13 Apr 2017 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-8/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chapter VII:Quantum Machine Learning</title>
      <link>https://mr-markovian.github.io/post/chapter-7/</link>
      <pubDate>Thu, 13 Apr 2017 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-7/</guid>
      <description>In the twinkling of an eye, all was ready to execute Coppenole’s idea. Bourgeois, scholars and law clerks all set to work. The little chapel situated opposite the marble table was selected for the scene of the grinning match. A pane broken in the pretty rose window above the door, left free a circle of stone through which it was agreed that the competitors should thrust their heads. In order to reach it, it was only necessary to mount upon a couple of hogsheads, which had been produced from I know not where, and perched one upon the other, after a fashion.</description>
    </item>
    
    <item>
      <title>Chapter IV: Time series in business science</title>
      <link>https://mr-markovian.github.io/post/chapter-4/</link>
      <pubDate>Wed, 12 Apr 2017 11:14:48 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-4/</guid>
      <description>While the pensioner of Ghent and his eminence were exchanging very low bows and a few words in voices still lower, a man of lofty stature, with a large face and broad shoulders, presented himself, in order to enter abreast with Guillaume Rym; one would have pronounced him a bull-dog by the side of a fox. His felt doublet and leather jerkin made a spot on the velvet and silk which surrounded him.</description>
    </item>
    
    <item>
      <title>Chapter 14: Give momentum to your samples</title>
      <link>https://mr-markovian.github.io/post/chapter-14/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-14/</guid>
      <description>Hamiltonian Monte Carlo methods</description>
    </item>
    
    <item>
      <title>Chapter 15: Bayesian Uncertainty and Statistics</title>
      <link>https://mr-markovian.github.io/post/chapter-15/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-15/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chapter II: Control theory</title>
      <link>https://mr-markovian.github.io/post/chapter-13/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-13/</guid>
      <description>Controlability
Observability
Identifiability
References  The Inductive bias of Quantum Kernels  </description>
    </item>
    
    <item>
      <title>Chapter II: Ensemble forecats for NWP: Why a best estimate is not a good idea</title>
      <link>https://mr-markovian.github.io/post/chapter-9/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-9/</guid>
      <description>Learn how to enbed a youtube link. Write a post. Singular Vector. Upscaleing of errors. AI and stochastically rounded low precision, enromous potential to imporve data assimilation schemes. AI to make better parametrizations. Signal to noise paradox paper(UK met office). There are some cases where the atmosphere is more predictable than the ensemble. The nonlinearity can confine the ensemble into narrow regions of phase space, which reduces the uncertainity. Mention of forecast based finance aid.</description>
    </item>
    
    <item>
      <title>Stochastic Parameterizations for Uncertainty, Prediction and Control</title>
      <link>https://mr-markovian.github.io/post/chapter-2/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-2/</guid>
      <description>Solving partial differential euqations using computers is done by converting it into ode via discretizations so that one can represent the systems using a finite degree of freedoms such that our approximations are still valid and we are able to estimate and solve the system at a coarser level. What this means is that we only use a finite number of points to represent a line, a finite number of area elements and a finite number of volume elements to construct algebraic equations in order to solve them using the computer.</description>
    </item>
    
    <item>
      <title>Chapter I: Optimization: The Nature&#39;s way</title>
      <link>https://mr-markovian.github.io/post/chapter-1/</link>
      <pubDate>Sun, 09 Apr 2017 10:58:08 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-1/</guid>
      <description>Three hundred and forty-eight years, six months, and nineteen days ago to-day, the Parisians awoke to the sound of all the bells in the triple circuit of the city, the university, and the town ringing a full peal.
The sixth of January, 1482, is not, however, a day of which history has preserved the memory. There was nothing notable in the event which thus set the bells and the bourgeois of Paris in a ferment from early morning.</description>
    </item>
    
    <item>
      <title>Contact me</title>
      <link>https://mr-markovian.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mr-markovian.github.io/contact/</guid>
      <description>We could be six handshakes apart. Let&amp;rsquo;s bring it closer
   Platform URL     Instagram: https://www.instagram.com/shashankkroy/   Facebook: https://www.facebook.com/shashank.roy1997/   Linkedin: https://www.linkedin.com/in/shashankroy/   mail: shashankroy1997@gmail.com , shashank.roy@icts.res.in   Mob. no.: +91-8002939890, +91-6200421519    Your Name Email Address An email address is required.  Message   </description>
    </item>
    
  </channel>
</rss>

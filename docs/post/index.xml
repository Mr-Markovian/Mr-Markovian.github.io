<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on Shashank&#39;s Home</title>
    <link>https://mr-markovian.github.io/post/</link>
    <description>Recent content in Articles on Shashank&#39;s Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Shashank Roy</copyright>
    <lastBuildDate>Mon, 11 Apr 2022 11:13:32 -0400</lastBuildDate><atom:link href="https://mr-markovian.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chapter III: Sinkhorn: A short intro to distance on probability measures for machine learning</title>
      <link>https://mr-markovian.github.io/post/chapter-3/</link>
      <pubDate>Mon, 11 Apr 2022 11:13:32 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-3/</guid>
      <description>Given a set of observations ${y1:y_n} \in \mathcal{X}$ which are samples from an unknown distribution $p(y)$, suppose that we would like to produce new samples similar to the above. What one then means is that they are tyring to learn the distribution $p(y)$ itself, through which they can sample new points. A model which will learn the distribuion from the samples and then generate samples from it is called a generative model.</description>
    </item>
    
    <item>
      <title>Machine Learning for Weather and Climate Science</title>
      <link>https://mr-markovian.github.io/post/chapter-10/</link>
      <pubDate>Sun, 13 Jun 2021 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-10/</guid>
      <description>It&amp;rsquo;s a remarkable time for us for application of AI to solve the hardest of real world problems. Climate and weather prediction is one such task which impacts billions of people all over the world.
Of possible areas, some are as follows:
 Downscale data Accelerate Simulations Improve forecasts Emulate complex processes   Pattern recognition for extreme weather phenomenon. Tracking extreme events is critical for our climate if one is to prepare and avoid their devastations.</description>
    </item>
    
    <item>
      <title>Chapter VI: Quantum Alorithms for Optimization</title>
      <link>https://mr-markovian.github.io/post/chapter-11/</link>
      <pubDate>Fri, 14 Apr 2017 11:25:05 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-11/</guid>
      <description>$$\mathcal{H}=\sum_{j,j}s_i s_j$$ Solving optimzation probelms, which deal in finding the best possible solution to a problem under certain constrained. Often at the heart of critical decision making processes in industrial and business problems which are both complex and high-dimensional in nature. Under some conditions, they sometimes become notoriously hard and often ones resorts to best achievable solutions instead of the best solution. To take a refresher of the classical optimization problems as we know it, click here.</description>
    </item>
    
    <item>
      <title>Chapter VI: Tensor networks for Machine Learning</title>
      <link>https://mr-markovian.github.io/post/chapter-12/</link>
      <pubDate>Fri, 14 Apr 2017 11:25:05 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-12/</guid>
      <description>Tensor Networks Graphical models are powerful methods which simplifies the statistical dependence of a set of random variables.
 Bayesian networks Markov Random Fields factor graph model  A factor graphical model descibes a fucntion of the random variables in temrs of the products of fuction of this random variables. when all the factors are non ngative fucntion, the global fucntion can be used to represent a multivariate probability distribution. they capture and can model a lot of problems in fiels of economics, machine learning, statistical modeling and so on.</description>
    </item>
    
    <item>
      <title>Monte Carlo Methods: The Wisdom of the Crowd</title>
      <link>https://mr-markovian.github.io/post/chapter-6/</link>
      <pubDate>Fri, 14 Apr 2017 11:25:05 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chaos: It&#39;s more than the butterfly effect</title>
      <link>https://mr-markovian.github.io/post/chapter-8/</link>
      <pubDate>Thu, 13 Apr 2017 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-8/</guid>
      <description>References Tim Palmer&amp;rsquo;s paper Edward Lorenz Paper</description>
    </item>
    
    <item>
      <title>Ensemble Kalman Filters</title>
      <link>https://mr-markovian.github.io/post/chapter-7/</link>
      <pubDate>Thu, 13 Apr 2017 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-7/</guid>
      <description>Kalman filter is a sequetial state estimation algorithms which performs the filtering-step recursively based on the assumption of linearity and gaussian density functions of the system which allows it to recursively implement the bayesian posterior calculation by simply updating mean and covariance whenever observations are available.
Proposed by G.Evensen, Ensemble Kalman filters are a Monte-Carlo approch of approximation of the original Kalman filter.The filter employs ensemble representation of probability distributions as a collection states drawn from the respective pdfs.</description>
    </item>
    
    <item>
      <title>Metaheuristic Optimization and evolutionary algorithms: How nature solves it&#39;s problems</title>
      <link>https://mr-markovian.github.io/post/chapter-5/</link>
      <pubDate>Thu, 13 Apr 2017 11:15:58 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chapter IV: Time series in business science</title>
      <link>https://mr-markovian.github.io/post/chapter-4/</link>
      <pubDate>Wed, 12 Apr 2017 11:14:48 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-4/</guid>
      <description>While the pensioner of Ghent and his eminence were exchanging very low bows and a few words in voices still lower, a man of lofty stature, with a large face and broad shoulders, presented himself, in order to enter abreast with Guillaume Rym; one would have pronounced him a bull-dog by the side of a fox. His felt doublet and leather jerkin made a spot on the velvet and silk which surrounded him.</description>
    </item>
    
    <item>
      <title>Chapter 14: Give momentum to your samples</title>
      <link>https://mr-markovian.github.io/post/chapter-14/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-14/</guid>
      <description>Hamiltonian Monte Carlo methods</description>
    </item>
    
    <item>
      <title>Chapter 15: Bayesian Uncertainty and Statistics</title>
      <link>https://mr-markovian.github.io/post/chapter-15/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-15/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chapter II: Control theory</title>
      <link>https://mr-markovian.github.io/post/chapter-13/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-13/</guid>
      <description>Controlability
Observability
Identifiability
References  The Inductive bias of Quantum Kernels  </description>
    </item>
    
    <item>
      <title>Chapter II: Ensemble forecats for NWP: Why a best estimate is not a good idea</title>
      <link>https://mr-markovian.github.io/post/chapter-9/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-9/</guid>
      <description>Learn how to enbed a youtube link. Write a post. Singular Vector. Upscaleing of errors. AI and stochastically rounded low precision, enromous potential to imporve data assimilation schemes. AI to make better parametrizations. Signal to noise paradox paper(UK met office). There are some cases where the atmosphere is more predictable than the ensemble. The nonlinearity can confine the ensemble into narrow regions of phase space, which reduces the uncertainity. Mention of forecast based finance aid.</description>
    </item>
    
    <item>
      <title>Stochastic Parameterizations for Uncertainty, Prediction and Control</title>
      <link>https://mr-markovian.github.io/post/chapter-2/</link>
      <pubDate>Mon, 10 Apr 2017 11:00:59 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-2/</guid>
      <description>Solving partial differential euqations using computers is done by converting it into ode via discretizations so that one can represent the systems using a finite degree of freedoms such that our approximations are still valid and we are able to estimate and solve the system at a coarser level. What this means is that we only use a finite number of points to represent a line, a finite number of area elements and a finite number of volume elements to construct algebraic equations in order to solve them using the computer.</description>
    </item>
    
    <item>
      <title>A short introduction to Data Assimilation</title>
      <link>https://mr-markovian.github.io/post/chapter-1/</link>
      <pubDate>Sun, 09 Apr 2017 10:58:08 -0400</pubDate>
      
      <guid>https://mr-markovian.github.io/post/chapter-1/</guid>
      <description>Data assimilation research addresses two problems of inverse modeling which are filtering and prediction. Filtering is defined as the sequential estimation of the posterior distribution in phase space of the state of a physical system based on a priori assumed model and available observations. Filtering is followed by prediction, where the goal is to quanitfy the the future of the system and it&amp;rsquo;s flow dependent uncertainty which accounts for possible source of error.</description>
    </item>
    
  </channel>
</rss>
